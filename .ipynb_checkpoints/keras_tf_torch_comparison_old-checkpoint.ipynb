{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test of bert implementation in keras\n",
    "\n",
    "Here I compare the output of the keras implementation to the torch and tensorflow ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Michi/Google Drive/pi_school/bert_keras_mine\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Michi/anaconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('../') \n",
    "\n",
    "import numpy as np\n",
    "from extract_features import get_bert_embeddings\n",
    "from modeling import PreTrainedBertModel\n",
    "import keras.backend as K\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Keras results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                           'Who was Jim Henson ? Jim Henson was a puppeteer',\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_question = np.array(['Who was Jim Henson ? ||| Jim Henson was a puppeteer']) #, \\\n",
    "\"\"\"\n",
    "                           'Who was Jim Henson ? Jim Henson was a puppeteer',\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set this path to the folder where the pre-trained bert model is\n",
    "# base_dir = '../'\n",
    "\n",
    "model_dir='pre_trained_models/multilingual_embeddings_old/'\n",
    "data_dir='results/'\n",
    "\n",
    "#vocab_path = model_dir+'vocab.txt'\n",
    "#model_path = model_dir+'bert_model.ckpt'\n",
    "#config_path=model_dir+'bert_config.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ BERT model built. \n",
      "------ Filling with pre-trained weights... \n"
     ]
    }
   ],
   "source": [
    "model_pre_trained = PreTrainedBertModel(model_dir, batch_size=1, Verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_embedding_layer = get_bert_embeddings(model_pre_trained, dummy_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#layer_indexes = list(range(len(my_embedding_layer.shape)))\n",
    "#layer_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st index: select layers output\n",
    "# 2nd index: number of layer (from 0 to 11, last (output) layer is 0)\n",
    "# 3rd index: input sentence index (len(batchsize))\n",
    "# 4th index: token index (0 is [CLS])\n",
    "\n",
    "K.eval(my_embedding_layer).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# list of embedding vector of [CLS] token for entry 1 and 2\n",
    "\n",
    "keras_outputs = K.eval(my_embedding_layer)\n",
    "\n",
    "#keras_outputs = [out[:,0,:] for out in keras_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "batch_size = keras_outputs.shape[0]\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11857092  0.08033587  0.31774449  0.06451874 -0.07478599]\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    print(keras_outputs[i,0,:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Google's bert results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Who was Jim Henson ? ||| Jim Henson was a puppeteer'], \n",
       "      dtype='<U51')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "! data_dir=results/; echo 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' \\\n",
    "> $data_dir/input_dummy.txt\n",
    "#echo 'Who was Jim Henson ? Jim Henson was a puppeteer' >> $data_dir/input_dummy.txt;\\\n",
    "#echo 'Frase completamente a caso in italiano' >> $data_dir/input_dummy.txt;\\\n",
    "#echo 'Ãˆ forse questa una nuova domanda test?' >> $data_dir/input_dummy.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If the following cell gives a memory error, run it in a terminal, or try to shut down the kernel and restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Michi/anaconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Traceback (most recent call last):\n",
      "  File \"bert_google/extract_features.py\", line 419, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/Users/Michi/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n",
      "    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n",
      "  File \"bert_google/extract_features.py\", line 353, in main\n",
      "    is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
      "AttributeError: module 'tensorflow.contrib.tpu' has no attribute 'InputPipelineConfig'\n",
      "CPU times: user 97.1 ms, sys: 44.1 ms, total: 141 ms\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! BERT_BASE_DIR=pre_trained_models/multilingual_embeddings; DATA_DIR=results/; source activate py36;\\\n",
    "python bert_google/extract_features.py \\\n",
    "  --input_file=$DATA_DIR'input_dummy.txt' \\\n",
    "  --output_file=$DATA_DIR'output_dummy_google.jsonl' \\\n",
    "  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n",
    "  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n",
    "  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n",
    "  --layers=-1\\\n",
    "  --max_seq_length=128 \\\n",
    "  --batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(data_dir+'output_dummy_google.jsonl', 'r') as f:\n",
    "    result_google = [json.loads(jline) for jline in f.read().split('\\n')[:-1]]\n",
    "print(len(result_google))\n",
    "print(len(result_google[0]))\n",
    "print(result_google[0].keys())\n",
    "print(\"number of tokens\", len(result_google))\n",
    "print(\"number of layers\", len(result_google[0]['features'][0]['layers']))\n",
    "print(\"hidden_size\", len(result_google[0]['features'][0]['layers'][0]['values']))\n",
    "print(len(result_google[0]['features'][0]['layers'][0]['values']))\n",
    "\n",
    "google_outputs=[]\n",
    "for token_check_index in range(batch_size):\n",
    "    google_outputs.append(list(np.array(result_google[token_check_index]['features'][0]['layers'][t]['values']) for t in layer_indexes))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Quick comparison of first values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(result_google[0]['features'][0]['token'])\n",
    "for i in range(batch_size):\n",
    "    print(result_google[i]['features'][0]['layers'][0]['values'][:3])\n",
    "    print(google_outputs[i][0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pytorch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE                 \u001b[34mnotebooks\u001b[m\u001b[m               setup.py\r\n",
      "README.md               \u001b[34mpytorch_pretrained_bert\u001b[m\u001b[m \u001b[34mtests\u001b[m\u001b[m\r\n",
      "\u001b[34mbin\u001b[m\u001b[m                     requirements.txt\r\n",
      "\u001b[34mexamples\u001b[m\u001b[m                \u001b[34msamples\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls bert_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"bert_torch/examples/extract_features.py\", line 28, in <module>\n",
      "    from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
      "ImportError: cannot import name SequentialSampler\n",
      "CPU times: user 19.7 ms, sys: 16.9 ms, total: 36.6 ms\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! DATA_DIR=results/; python bert_torch/examples/extract_features.py \\\n",
    "  --input_file=$DATA_DIR'input_dummy.txt' \\\n",
    "  --output_file=$DATA_DIR'output_dummy_torch.jsonl' \\\n",
    "  --bert_model=bert-base-multilingual\\\n",
    "  --layers=-1\\\n",
    "  --max_seq_length=128\\\n",
    "  #--no_cuda=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(data_dir+'output_dummy_torch.jsonl', 'r') as f:\n",
    "    result_torch = [json.loads(jline) for jline in f.read().split('\\n')[:-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(result_torch))\n",
    "print(len(result_torch[0]))\n",
    "print(result_torch[0].keys())\n",
    "print(\"number of tokens\", len(result_torch))\n",
    "print(\"number of layers\", len(result_torch[0]['features'][0]['layers']))\n",
    "print(\"hidden_size\", len(result_torch[0]['features'][0]['layers'][0]['values']))\n",
    "len(result_torch[0]['features'][0]['layers'][0]['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pytorch_outputs=[]\n",
    "for token_check_index in range(batch_size):\n",
    "    pytorch_outputs.append(list(np.array(result_torch[token_check_index]['features'][0]['layers'][t]['values']) for t in layer_indexes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    print(result_torch[i]['features'][0]['token'])\n",
    "    print(result_torch[i]['features'][0]['layers'][0]['values'][:3])\n",
    "    print(pytorch_outputs[i][0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Final comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for token_check_index in range(batch_size):\n",
    "    print(\"Unique token id: %s\" %token_check_index)\n",
    "    print('shape google layer, shape keras layer, standard deviation')\n",
    "    \n",
    "    print('\\n'.join(list(str((np.array(google_outputs[token_check_index][0]).shape,\n",
    "                          np.array(keras_outputs[0][token_check_index,0,:]).shape, \n",
    "                          np.sqrt(np.mean((np.array(keras_outputs[i][token_check_index,0,:]) \\\n",
    "                                           - np.array(google_outputs[token_check_index][i]))**2.0)))) \\\n",
    "                         for i in range(12))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for token_check_index in range(batch_size):\n",
    "    print(\"Unique token id: %s\" %token_check_index)\n",
    "    print('shape torch layer, shape keras layer, standard deviation')\n",
    "    \n",
    "    print('\\n'.join(list(str((np.array(pytorch_outputs[token_check_index][0]).shape,\n",
    "                          np.array(keras_outputs[0][token_check_index,0,:]).shape, \n",
    "                          np.sqrt(np.mean((np.array(keras_outputs[i][token_check_index,0,:]) \\\n",
    "                                           - np.array(pytorch_outputs[token_check_index][i]))**2.0)))) \\\n",
    "                         for i in range(12))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for token_check_index in range(batch_size):\n",
    "    print(\"Unique token id: %s\" %token_check_index)\n",
    "    print('shape torch layer, shape google layer, standard deviation')\n",
    "    \n",
    "    print('\\n'.join(list(str((np.array(pytorch_outputs[token_check_index][0]).shape,\n",
    "                          np.array(google_outputs[token_check_index][0]).shape, \n",
    "                          np.sqrt(np.mean((np.array(google_outputs[token_check_index][i]) \\\n",
    "                                           - np.array(pytorch_outputs[token_check_index][i]))**2.0)))) \\\n",
    "                         for i in range(12))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The above results can easily be extended to compare all the tokens for the given sequence. I checked that they give a standerd deviation of the same order of magnitude. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
